{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.sklearn_api import W2VTransformer\n",
    "from gensim.test.utils import common_texts\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF = pd.read_csv(\"preprocessed2.csv\")\n",
    "\n",
    "tweetsDF.drop(labels=[\"Unnamed: 0\",\n",
    "                      \"airline\", \n",
    "                      \"negativereason\", \n",
    "                      \"airline_sentiment_confidence\", \n",
    "                      \"negativereason\",\n",
    "                      \"airline_sentiment\",\n",
    "                      ], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet2words</th>\n",
       "      <th>num_capitalized</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>num_negative_words</th>\n",
       "      <th>num_positive_words</th>\n",
       "      <th>num_neutral_words</th>\n",
       "      <th>has_capitalized</th>\n",
       "      <th>num_capitalised_positive_words</th>\n",
       "      <th>num_capitalised_negative_words</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_special_character</th>\n",
       "      <th>correctedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.160358</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>1</td>\n",
       "      <td>What said</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>What said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>1</td>\n",
       "      <td>plus added commercials experience tacky</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>plus added commercials experience tacky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.160358</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>1</td>\n",
       "      <td>I today Must mean I need take another trip</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>I today Must mean I need take another trip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.703300</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0</td>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>really aggressive blast obnoxious entertainme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "      <td>really big bad thing</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>really big bad thing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   negativereason_confidence  \\\n",
       "0                  13.160358   \n",
       "1                   0.000000   \n",
       "2                  13.160358   \n",
       "3                   0.703300   \n",
       "4                   1.000000   \n",
       "\n",
       "                                                text  sentiment  \\\n",
       "0                @VirginAmerica What @dhepburn said.          1   \n",
       "1  @VirginAmerica plus you've added commercials t...          1   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...          1   \n",
       "3  @VirginAmerica it's really aggressive to blast...          0   \n",
       "4  @VirginAmerica and it's a really big bad thing...          0   \n",
       "\n",
       "                                         tweet2words  num_capitalized  \\\n",
       "0                                          What said                0   \n",
       "1            plus added commercials experience tacky                0   \n",
       "2         I today Must mean I need take another trip                0   \n",
       "3  really aggressive blast obnoxious entertainmen...                0   \n",
       "4                               really big bad thing                0   \n",
       "\n",
       "   tweet_length  num_negative_words  num_positive_words  num_neutral_words  \\\n",
       "0             3                   0                   0                  4   \n",
       "1             6                   0                   0                  9   \n",
       "2             8                   0                   0                 12   \n",
       "3            11                   2                   0                 15   \n",
       "4             5                   1                   0                  9   \n",
       "\n",
       "   has_capitalized  num_capitalised_positive_words  \\\n",
       "0                1                               0   \n",
       "1                0                               0   \n",
       "2                1                               0   \n",
       "3                0                               0   \n",
       "4                0                               0   \n",
       "\n",
       "   num_capitalised_negative_words  num_hashtags  num_special_character  \\\n",
       "0                               0             0                      3   \n",
       "1                               0             0                      4   \n",
       "2                               0             0                      4   \n",
       "3                               0             0                      5   \n",
       "4                               0             0                      2   \n",
       "\n",
       "                                       correctedText  \n",
       "0                                          What said  \n",
       "1            plus added commercials experience tacky  \n",
       "2         I today Must mean I need take another trip  \n",
       "3   really aggressive blast obnoxious entertainme...  \n",
       "4                               really big bad thing  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentences(object):\n",
    "    def stemming(self):\n",
    "        '''\n",
    "        Apply stemming to each token\n",
    "\n",
    "        @return:\n",
    "            Return a list of stemmed tokens\n",
    "        '''\n",
    "        stemmer = SnowballStemmer(\"english\") \n",
    "        words = []\n",
    "\n",
    "        self.__splitIntoIndividualsTokens__()\n",
    "        # words = [w.split() for w in tokens]\n",
    "        stemmed = [w for w in self.individualTokens]\n",
    "        return stemmed\n",
    "    \n",
    "    def __splitIntoIndividualsTokens__(self):\n",
    "        self.individualTokens = list()\n",
    "        for w in self.tokens:\n",
    "            try:\n",
    "                self.individualTokens.append(w.split())\n",
    "            except AttributeError:\n",
    "                self.individualTokens.append(\"\")\n",
    "    \n",
    "    def __init__(self, tokens):\n",
    "        self.tokens = tokens\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return(str(self.tokens))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(len(self.tokens))\n",
    "    \n",
    "    def __iter__(self):\n",
    "#         self.tokens = self.stemming()\n",
    "        yield self.tokens\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['What', 'said'],\n",
       " ['plus', 'added', 'commercials', 'experience', 'tacky'],\n",
       " ['I', 'today', 'Must', 'mean', 'I', 'need', 'take', 'another', 'trip'],\n",
       " ['really',\n",
       "  'aggressive',\n",
       "  'blast',\n",
       "  'obnoxious',\n",
       "  'entertainment',\n",
       "  'guests',\n",
       "  'faces',\n",
       "  'amp',\n",
       "  'little',\n",
       "  'recourse'],\n",
       " ['really', 'big', 'bad', 'thing']]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentences = Sentences(tweetsDF['correctedText'].tolist()) # a memory-friendly iterator\n",
    "tweetsList = tweetsDF['correctedText'].tolist()\n",
    "\n",
    "\n",
    "onlyWords = list()\n",
    "for w in tweetsList:\n",
    "    try:\n",
    "        onlyWords.append(list(w.split()))\n",
    "    except AttributeError:\n",
    "        onlyWords.append([\"\"])\n",
    "onlyWords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = W2VTransformer(size=10, min_count=5, seed=1)\n",
    "\n",
    "try: \n",
    "    wordvecs = model.fit(onlyWords[:5000]).transform(onlyWords[5000:])\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "W2VTransformer(alpha=0.025, batch_words=10000, cbow_mean=1,\n",
       "        hashfxn=<built-in function hash>, hs=0, iter=5,\n",
       "        max_vocab_size=None, min_alpha=0.0001, min_count=5, negative=5,\n",
       "        null_word=0, sample=0.001, seed=1, sg=0, size=10, sorted_vocab=1,\n",
       "        trim_rule=None, window=5, workers=3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
