{"cells":[
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Analysis of text content of tweets\n\nIf graphs are not displayed properly, please visit the jupyter notebooks in my github account [https://github.com/solegalli/DataScience-Portfolio](https://github.com/solegalli/DataScience-Portfolio/tree/master/AirlineSentimentAnalysis)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "options(jupyter.plot_mimetypes = \"image/png\")"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "data = read.csv('../input/Tweets.csv')\nlibrary(dplyr)\ndata = select(data,airline_sentiment, negativereason, airline, text)\nhead(data)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Every tweet begins with a @airline tag, which indicates the airline towards which the message is directed. To analyse the content of the tweet, this part is not relevant, so it will be removed from the tweet texts."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Remove the @airline bit of the text of the tweet\ndata$text = gsub(\"^@\\\\w+ *\", \"\", data$text)\nhead(data)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "We can see now, that the tweets do not contain the @airline tag. They are ready to be processed. Tweets classified as negative or positive will be analysed separately."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# divide tweets in 2 dataframes according to positive or negative sentiment\npositive = subset(data, airline_sentiment == 'positive')\nnegative = subset(data, airline_sentiment == 'negative')\ndim(positive); dim(negative)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "We see that from the total amount of tweets (14640), 2363 have been clasified as positive and 9178 as negative.\n\n## Determine word frequency and build cloud of words for each sentiment"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "library(tm); library(SnowballC)\nlibrary(wordcloud)\n\n# these words appear quite frequently in tweets and in my opinion are not informative,\n# so I will remove them\"\nwordsToRemove = c('get', 'cant', 'can', 'now', 'just', 'will', 'dont', 'ive', 'got', 'much')\n\n# generate a function to analyse corpus text\nanalyseText = function(text_to_analyse){\n    # analyse text and generate matrix of words\n    # Returns a dataframe containing 1 tweet per row, one word per column\n    # and the number of times the word appears per tweet\n    CorpusTranscript = Corpus(VectorSource(text_to_analyse))\n    CorpusTranscript = tm_map(CorpusTranscript, content_transformer(tolower), lazy = T)\n    CorpusTranscript = tm_map(CorpusTranscript, PlainTextDocument, lazy = T)\n    CorpusTranscript = tm_map(CorpusTranscript, removePunctuation)\n    CorpusTranscript = tm_map(CorpusTranscript, removeWords, wordsToRemove)\n    CorpusTranscript = tm_map(CorpusTranscript, removeWords, stopwords(\"english\"))\n    CorpusTranscript = DocumentTermMatrix(CorpusTranscript)\n    CorpusTranscript = removeSparseTerms(CorpusTranscript, 0.97) # keeps a matrix 97% sparse\n    CorpusTranscript = as.data.frame(as.matrix(CorpusTranscript))\n    colnames(CorpusTranscript) = make.names(colnames(CorpusTranscript))\n    \n    return(CorpusTranscript)\n}"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "words = analyseText(negative$text)\ndim(words)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "The function has extracted 30 words (1 per column) that are repeated with certain frequency accross all negative tweets. Each column specifies how many times that specific word appeared in each tweet (in each row). The sum of the column specifies how many times that specific word was used altogether in all negative tweets."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# sum the number of times each word appears in total accross all negative tweets.\nfreqWords_neg = colSums(words)\nfreqWords_neg = freqWords_neg[order(freqWords_neg, decreasing = T)]\nhead(freqWords_neg)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "We see for example that the word flight appeared 2901 times considering all negative tweets, and the word cancelled appeared 920 times."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# analysis of positive tweets\nwords = analyseText(positive$text)\ndim(words)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "The function has determined 18 words that appear with certain frequency accross positive tweets."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "freqWords_pos = colSums(words)\nfreqWords_pos = freqWords_pos[order(freqWords_pos, decreasing = T)]\nhead(freqWords_pos)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "As \"thank\" and \"thanks\" are conveying the same message, I will sumarise them in one column."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# combine thanks and remove extra column\nfreqWords_pos[1] = freqWords_pos[1] + freqWords_pos[2]\nfreqWords_pos = freqWords_pos[-2]\nhead(freqWords_pos)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "We see that the word thanks appears 1061 times accross positive tweets, flight 373 times and so on."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# word clouds\npar(mfrow = c(1,2))\n\nwordcloud(freq = as.vector(freqWords_neg), words = names(freqWords_neg),random.order = FALSE,\n          random.color = FALSE, colors = brewer.pal(9, 'Reds')[4:9])\n\nwordcloud(freq = as.vector(freqWords_pos), words = names(freqWords_pos),random.order = FALSE,\n          random.color = FALSE, colors = brewer.pal(9, 'BuPu')[4:9])"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "The cloud of words provide a nice visual representation of the word frequency for each type of sentiment (negative: left or positive: right). The size of the word correlates with its frequency accross all tweets. We can get an idea of what people are talking about. For example, for negative sentiment, people seem to complain about cancelled or delayed flights, and hours waiting. However, for positive sentiment, people are mostly thankful and they talk about great service/flight.\n\nIn the following section, I will analyse the association between words, i.e., words that usually are mentioned together in tweets. "
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# generate a function to analyse corpus text and return a document term matrix instead of dataframe\n# we can perform further analysis on document term matrices\nanalyseText2 = function(text_to_analyse){\n    # analyse text and generate matrix of words\n    # Returns a dtm containing 1 tweet per row, one word per column\n    # and the number of times the word appears per tweet\n    CorpusTranscript = Corpus(VectorSource(text_to_analyse))\n    CorpusTranscript = tm_map(CorpusTranscript, content_transformer(tolower), lazy = T)\n    CorpusTranscript = tm_map(CorpusTranscript, PlainTextDocument, lazy = T)\n    CorpusTranscript = tm_map(CorpusTranscript, removePunctuation)\n    CorpusTranscript = tm_map(CorpusTranscript, removeWords, wordsToRemove)\n    CorpusTranscript = tm_map(CorpusTranscript, removeWords, stopwords(\"english\"))\n    CorpusTranscript = DocumentTermMatrix(CorpusTranscript)\n    CorpusTranscript = removeSparseTerms(CorpusTranscript, 0.97) # keeps a matrix 97% sparse\n    \n    return(CorpusTranscript)\n}"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "words_neg = analyseText2(negative$text)\n# find words correlated with the ones mentioned below (correlation at 70%)\nfindAssocs(words_neg, c(\"flight\", 'customer', 'gate', 'phone'), .07)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "We see that in negative tweets, the appearance of the word flight correlates with the appearance of the words cancelled, late and delayed, indicating that people are complaining about delayed flights. The word customer is associated with the word service, which is expected, as customer service was a recurrent issue in negative tweets. Interestingly, the word gate is associated with the words waiting and plane, which probably means that people were left waiting at the gate for some time before departure.\nSo from this study, and without having read any tweet, we understand that people are generally complaining about."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "words_pos = analyseText2(positive$text)\nfindAssocs(words_pos, c(\"flight\", 'awesome', 'amazing', 'service'), .07)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "For positive sentiment tweets, we observe that the word flight is associated with great, suggesting that people have had great flight experiences. The word amazing is associated with the word customer, which is in turn associated with the word service, indicating that people experienced an amazing customer service in many opportunities. Similarly, without having actually read any tweet, with this analysis we get an idea of what people are saying about the airlines.\n\n### To further understand the associations between words, we can make clustering analysis of words."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# hierarchical clustering\nd = dist(t(as.matrix(words_neg)), method = 'euclidean')\nfit = hclust(d = d, method = 'ward.D')\n\n#fancy plot\nop = par(bg = \"#DDE3CA\")\nplot(fit, col = \"#487AA1\", col.main = \"#45ADA8\", col.lab = \"#7C8071\", main = 'Negative Sentiment', xlab = '',\n     col.axis = \"#F38630\", lwd = 3, lty = 3, sub = \"\", hang = -1, axes = FALSE)\n# add axis\naxis(side = 2, at = seq(0, 400, 100), col = \"#F38630\", labels = FALSE, \n     lwd = 2)\n# add text in margin\nmtext(seq(0, 100, 10), side = 2, at = seq(0, 100, 10), line = 1, \n      col = \"#A38630\", las = 2)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "In the dendrogram, words that are linked by short arms are highly associated."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "plot.new()\nplot(fit, hang=-1, main = 'Negative Sentiment', xlab = '')\nrect.hclust(fit, k=4, border=\"red\")"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Although the dendrogram does not seem to be particularly informative, we observe again the association of words like customer and service, and cancelled flight. Words that reflect complains more generally, like waiting, bag (presumably lost), hours, time, hold, cluster altogether."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# positive sentiment tweets\nd = dist(t(as.matrix(words_pos)), method = 'euclidean')\nfit = hclust(d = d, method = 'ward.D')\n\n#fancy plot\nop = par(bg = \"#DDE3CA\")\nplot(fit, col = \"#487AA1\", col.main = \"#45ADA8\", col.lab = \"#7C8071\", main = 'Positive Sentiment', xlab = '',\n     col.axis = \"#F38630\", lwd = 3, lty = 3, sub = \"\", hang = -1, axes = FALSE)\n# add axis\naxis(side = 2, at = seq(0, 400, 100), col = \"#F38630\", labels = FALSE, \n     lwd = 2)\n# add text in margin\nmtext(seq(0, 100, 10), side = 2, at = seq(0, 100, 10), line = 1, \n      col = \"#A38630\", las = 2)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "The positive tweet dendrogram is somewhat more informative. We can see the association of customer-service, and best-airline, or love-guys, good-time, which indicate more clearly, what the experience of the airline client was.\n\n### k-means clustering"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "library(fpc)   \nd = dist(t(as.matrix(words_neg)), method=\"euclidean\")   \nkfit = kmeans(d, 3)   \nclusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0, cex = 0.4, main = 'Negative Sentiment')"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "d = dist(t(as.matrix(words_pos)), method=\"euclidean\")   \nkfit = kmeans(d, 3)   \nclusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0, cex = 0.4, main = 'Positive Sentiment')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "K-means clustering is another method to determine the proximity of words (which indicates words that are presumably used together). The cluster plots displayed above, however do not shade new light into what we have previously discovered from the text of these tweets. I leave them just to show what we can do in terms of basic text analytics.\nIn the next and final section (part 3), I will build a model to predict the sentiment of tweets based on their text and other characteristics."
 }
],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"}}, "nbformat": 4, "nbformat_minor": 0}