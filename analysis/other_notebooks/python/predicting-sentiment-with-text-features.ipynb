{"cells":[{"metadata":{"_uuid":"ac0125127a55e4d120e4de2a056c584aeb0a0e99","_cell_guid":"02bcad77-7615-476a-996d-06b867f9bf82"},"cell_type":"markdown","source":"# Introduction\nIn this notebook I will explore techniques to use text data as input for a classification. The [Twitter US Airline Sentiment data set](https://www.kaggle.com/crowdflower/twitter-airline-sentiment) looks like a nice data set to work with. So let's take off!"},{"metadata":{"_uuid":"bef30704a2c497f940d64b4486508903444f295e","_cell_guid":"d7e01705-75cb-480b-b9c6-ca9edf5334b1"},"cell_type":"markdown","source":"# Importing modules"},{"metadata":{"collapsed":true,"_uuid":"2fec7805d8d0e999fc405d136beff46ac331b963","_cell_guid":"21cee267-f257-4ba3-88e1-d22e2fc57c7e","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \npd.set_option('display.max_colwidth', -1)\nfrom time import time\nimport re\nimport string\nimport os\nimport emoji\nfrom pprint import pprint\nimport collections\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\nsns.set(font_scale=1.3)\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.metrics import classification_report\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.externals import joblib\n\nimport gensim\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nnp.random.seed(37)","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"f60c7c8463a6c6143608f055a4c3ba9ba3c4a4c6","_cell_guid":"70ef7b60-cc3a-43ff-9cec-a3e9e1638af4"},"cell_type":"markdown","source":"# Loading the data\nWe shuffle the data frame in case the classes would be sorted. This can be done with the **reindex** method applied on the **permutation** of the original indices. In this notebook we will only focus on the text variable and the class variable."},{"metadata":{"collapsed":true,"_uuid":"cb12f1648e335f18109757da2f90a99afc35a754","_cell_guid":"4d569df8-dbb0-49e8-afcd-2a464af497ce","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/Tweets.csv')\ndf = df.reindex(np.random.permutation(df.index))  \ndf = df[['text', 'airline_sentiment']]","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"878a5d96c41b5f10158e6c915ee70e9cf1a63cb3","_cell_guid":"9e32eb35-b009-46c3-8fc1-fc5b2b48b6d3"},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"_uuid":"d6755361c07a2d13ef9965acd588c015dd3da916","_cell_guid":"c727d86e-65cb-4127-b665-54a0886b9fe0"},"cell_type":"markdown","source":"## Target variable\nThere are three class labels to predict: *negative, neutral or positive*. \n\n**CONCLUSION: **The class labels are **imbalanced** as we can see below. This is something that we should keep in mind during the model training phase. We could, for instance, make sure the classes are balanced by up/undersampling."},{"metadata":{"collapsed":true,"_uuid":"b91eff31d2a08fce8f7649bdd0656059604ff060","_cell_guid":"9ac8a71b-adfa-4c54-9283-f09f5ea82089","trusted":false},"cell_type":"code","source":"sns.factorplot(x=\"airline_sentiment\", data=df, kind=\"count\", size=6, aspect=1.5, palette=\"PuBuGn_d\")\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"818dbfec79449a1bebffb8a782587aa6e9b1175a","_cell_guid":"a957af2c-5b4e-4cfa-98e2-03d0f81089b0"},"cell_type":"markdown","source":"## Text variable\nTo analyze the text variable we create a class **TextCounts**. In this class we compute some basic statistics on the text variable. This class can be used later in a Pipeline, as well.\n\n* **count_words** : number of words in the tweet\n* **count_mentions** : referrals to other Twitter accounts, which are preceded by a @\n* **count_hashtags** : number of tag words, preceded by a #\n* **count_capital_words** : number of uppercase words, could be used to *\"shout\"* and express (negative) emotions\n* **count_excl_quest_marks** : number of question or exclamation marks\n* **count_urls** : number of links in the tweet, preceded by http(s)\n* **count_emojis** : number of emoji, which might be a good indication of the sentiment"},{"metadata":{"collapsed":true,"_uuid":"bcc2afba20e5d041359c05ab3d8510716cdfc6dd","_cell_guid":"12b6b6db-df87-4494-ad89-caa68b14495c","trusted":false},"cell_type":"code","source":"class TextCounts(BaseEstimator, TransformerMixin):\n    \n    def count_regex(self, pattern, tweet):\n        return len(re.findall(pattern, tweet))\n    \n    def fit(self, X, y=None, **fit_params):\n        # fit method is used when specific operations need to be done on the train data, but not on the test data\n        return self\n    \n    def transform(self, X, **transform_params):\n        count_words = X.apply(lambda x: self.count_regex(r'\\w+', x)) \n        count_mentions = X.apply(lambda x: self.count_regex(r'@\\w+', x))\n        count_hashtags = X.apply(lambda x: self.count_regex(r'#\\w+', x))\n        count_capital_words = X.apply(lambda x: self.count_regex(r'\\b[A-Z]{2,}\\b', x))\n        count_excl_quest_marks = X.apply(lambda x: self.count_regex(r'!|\\?', x))\n        count_urls = X.apply(lambda x: self.count_regex(r'http.?://[^\\s]+[\\s]?', x))\n        # We will replace the emoji symbols with a description, which makes using a regex for counting easier\n        # Moreover, it will result in having more words in the tweet\n        count_emojis = X.apply(lambda x: emoji.demojize(x)).apply(lambda x: self.count_regex(r':[a-z_&]+:', x))\n        \n        df = pd.DataFrame({'count_words': count_words\n                           , 'count_mentions': count_mentions\n                           , 'count_hashtags': count_hashtags\n                           , 'count_capital_words': count_capital_words\n                           , 'count_excl_quest_marks': count_excl_quest_marks\n                           , 'count_urls': count_urls\n                           , 'count_emojis': count_emojis\n                          })\n        \n        return df","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"75373b34ac6eef2768612e70162caf6b121a4eab","_cell_guid":"4552bc28-6eb1-4f4f-8f73-a129ed0fad2f","trusted":false},"cell_type":"code","source":"tc = TextCounts()\ndf_eda = tc.fit_transform(df.text)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"18f7bdefa9a7fcab78e7e688b04b2d480a84ad66","_cell_guid":"41a7925a-af42-49c8-99db-aa6e361f6f4d"},"cell_type":"markdown","source":"It could be interesting to see how the TextStats variables relate to the class variable. Therefore we write a function **show_dist** that provides descriptive statistics and a plot per target class."},{"metadata":{"collapsed":true,"_uuid":"2ddbab218287cdcaa579764c555571031ffd6ab8","_cell_guid":"f0351435-3561-42a5-a5e8-55aa7209a964","trusted":false},"cell_type":"code","source":"def show_dist(df, col):\n    print('Descriptive stats for {}'.format(col))\n    print('-'*(len(col)+22))\n    print(df.groupby('airline_sentiment')[col].describe())\n    bins = np.arange(df[col].min(), df[col].max() + 1)\n    g = sns.FacetGrid(df, col='airline_sentiment', size=5, hue='airline_sentiment', palette=\"PuBuGn_d\")\n    g = g.map(sns.distplot, col, kde=False, norm_hist=True, bins=bins)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"681fa80920a7a34dc3486675310b7b2c1d4a9ed6","_cell_guid":"72d53891-ba09-4ec2-aa69-d827125167e5","trusted":false},"cell_type":"code","source":"# Add airline_sentiment to df_eda\ndf_eda['airline_sentiment'] = df.airline_sentiment","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"aa76ec64ad4d4eefcb086870e260bbe8e110f37a","_cell_guid":"1d7be179-d38c-4ed0-9c9d-dbacbf43c55d","trusted":false},"cell_type":"code","source":"show_dist(df_eda, 'count_words')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"93716e6681e5819a6e72ff56d9837e2271ba4929","_cell_guid":"16de18c8-b2f9-4621-8a3f-40c58b851c8c","trusted":false},"cell_type":"code","source":"show_dist(df_eda, 'count_mentions')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"240fb548e872ba664ba0261393792225aa1b1be0","_cell_guid":"d81673f2-6886-4a24-ac04-15af7e921299","trusted":false},"cell_type":"code","source":"show_dist(df_eda, 'count_hashtags')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"26238a6baf1ad6bf3e3b30a32f8c4ecd1c54fff5","_cell_guid":"e0d9c23e-03f7-4df4-a199-3b8f41f0e395","trusted":false},"cell_type":"code","source":"show_dist(df_eda, 'count_capital_words')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"3ca91505f402504320a6c937dd6be5c20cf5a1f1","_cell_guid":"24d3ae00-b2f0-4293-a785-048b409d4541","trusted":false},"cell_type":"code","source":"show_dist(df_eda, 'count_excl_quest_marks')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"23d339c124cd0ebc82d37be174133cfa2fbfca30","_cell_guid":"1e857eb3-e949-48d6-868c-9b8f123b401f","trusted":false},"cell_type":"code","source":"show_dist(df_eda, 'count_urls')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"68c73eeb67a2af80619c6dc5493050631d8cabf2","_cell_guid":"69ecdc4f-baf5-41dd-bcd5-f805af43325b","trusted":false},"cell_type":"code","source":"show_dist(df_eda, 'count_emojis')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0171d7539984e488d0cf1a3472854c998f58fcce","_cell_guid":"9bb024ed-3893-4eb0-b047-54ca1e7bced7"},"cell_type":"markdown","source":"**CONCLUSIONS: **\n* **The number of words** used in the tweets is rater low. Maximum number of words is 36 and there are even tweets with only 2 words. So we'll have to be careful during data cleaning not to remove too many words. On the other hand, the text processing will be faster. Negative tweets contain more words than neutral or positive tweets.\n* All tweets have at least one **mention**. Probably this is the result of extracting the tweets based on mentions in the Twitter data. There seems to be no difference in number of mentions with regard to the sentiment.\n* Most of the tweets do not contain **hash tags**. So probably this variable will not be retained during model training. Again, no difference in number of hash tags with regard to the sentiment.\n* Most of the tweets do not contain **capitalized words** and we do not see a difference in distribution between the sentiments.\n* The positive tweets seem to be using a bit more **exclamation or question marks**.\n* Most tweets do not contain a **URL**. \n* Most tweets do not use **emojis**."},{"metadata":{"_uuid":"416159ee3509b0953455c170e20cde4136279765","_cell_guid":"0db65f91-0c7e-4d77-98ab-2b0fff58f855"},"cell_type":"markdown","source":"# Text Cleaning\nBefore we start using the tweets' text we clean it. We'll do the this in the class CleanText:\n- remove the **mentions**, as we want to make the model generalisable to tweets of other airline companies too.\n- remove the **hash tag sign** (#) but not the actual tag as this may contain information\n- set all words to **lowercase**\n- remove all **punctuations**, including the question and exclamation marks\n- remove the **urls** as they do not contain useful information and we did not notice a distinction in the number of urls used between the sentiment classes\n- make sure the converted **emojis** are kept as one word. \n- remove **digits**\n- remove **stopwords**\n- apply the **PorterStemmer** to keep the stem of the words"},{"metadata":{"collapsed":true,"_uuid":"b0f586110aa644f90b64b95de139ec0697ac44a1","_cell_guid":"fe4f4723-ac9b-4e46-88d6-4631a961c7e7","trusted":false},"cell_type":"code","source":"class CleanText(BaseEstimator, TransformerMixin):\n    def remove_mentions(self, input_text):\n        return re.sub(r'@\\w+', '', input_text)\n    \n    def remove_urls(self, input_text):\n        return re.sub(r'http.?://[^\\s]+[\\s]?', '', input_text)\n    \n    def emoji_oneword(self, input_text):\n        # By compressing the underscore, the emoji is kept as one word\n        return input_text.replace('_','')\n    \n    def remove_punctuation(self, input_text):\n        # Make translation table\n        punct = string.punctuation\n        trantab = str.maketrans(punct, len(punct)*' ')  # Every punctuation symbol will be replaced by a space\n        return input_text.translate(trantab)\n\n    def remove_digits(self, input_text):\n        return re.sub('\\d+', '', input_text)\n    \n    def to_lower(self, input_text):\n        return input_text.lower()\n    \n    def remove_stopwords(self, input_text):\n        stopwords_list = stopwords.words('english')\n        # Some words which might indicate a certain sentiment are kept via a whitelist\n        whitelist = [\"n't\", \"not\", \"no\"]\n        words = input_text.split() \n        clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n        return \" \".join(clean_words) \n    \n    def stemming(self, input_text):\n        porter = PorterStemmer()\n        words = input_text.split() \n        stemmed_words = [porter.stem(word) for word in words]\n        return \" \".join(stemmed_words)\n    \n    def fit(self, X, y=None, **fit_params):\n        return self\n    \n    def transform(self, X, **transform_params):\n        clean_X = X.apply(self.remove_mentions).apply(self.remove_urls).apply(self.emoji_oneword).apply(self.remove_punctuation).apply(self.remove_digits).apply(self.to_lower).apply(self.remove_stopwords).apply(self.stemming)\n        return clean_X","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9090e16587d44743366073e753e3cd06898095d2","_cell_guid":"267c43d4-f2f0-4533-8e77-33c14243b7af"},"cell_type":"markdown","source":"To show how the cleaned text variable will look like, here's a sample."},{"metadata":{"collapsed":true,"_uuid":"97369e87f093479687791ee7dcb1bb3b69c30218","_cell_guid":"b8a27b57-3955-4e97-96f1-01f9c84dc8d4","trusted":false},"cell_type":"code","source":"ct = CleanText()\nsr_clean = ct.fit_transform(df.text)\nsr_clean.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4ceed8983cca2c30af7eedf346400c859ed15e0","_cell_guid":"da0be13b-9e22-4709-b83a-a451fb2f5569"},"cell_type":"markdown","source":"**NOTE: **One side-effect of text cleaning is that some rows do not have any words left in their text. For the CountVectorizer and TfIdfVectorizer this does not really pose a problem. However, for the Word2Vec algorithm this causes an error. There are different strategies that you could apply to deal with these missing values.\n\n* Remove the complete row, but in a production environment this is not really desirable.\n* Impute the missing value with some placeholder text like *[no_text]*\n* Word2Vec: use the average of all vectors\n\nHere we will impute with a placeholder text."},{"metadata":{"collapsed":true,"_uuid":"bba4e68eb15ae8eab41869a3403e910a763ac486","_cell_guid":"11567bee-dad6-4809-b4d6-a3203821c779","trusted":false},"cell_type":"code","source":"empty_clean = sr_clean == ''\nprint('{} records have no words left after text cleaning'.format(sr_clean[empty_clean].count()))\nsr_clean.loc[empty_clean] = '[no_text]'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d54ce955f07356f7cfe32960987ed86479a22d21","_cell_guid":"84c1dc74-508b-4c55-ab34-ada314997a02"},"cell_type":"markdown","source":"## Most frequent words\nNow that we have the cleaned text of the tweets, we can have a look at what are the most frequent words. Below we'll show the top 20 words. \n\n**CONCLUSION: **Not surprisingly the most frequent word is *flight*."},{"metadata":{"collapsed":true,"_uuid":"99669d586ab45ffef74b67125503ad6314722fea","_cell_guid":"6e8f0c19-8f1c-4d0d-9156-17a67d9d50d2","trusted":false},"cell_type":"code","source":"cv = CountVectorizer()\nbow = cv.fit_transform(sr_clean)\nword_freq = dict(zip(cv.get_feature_names(), np.asarray(bow.sum(axis=0)).ravel()))\nword_counter = collections.Counter(word_freq)\nword_counter_df = pd.DataFrame(word_counter.most_common(20), columns = ['word', 'freq'])\n\nfig, ax = plt.subplots(figsize=(12, 10))\nsns.barplot(x=\"word\", y=\"freq\", data=word_counter_df, palette=\"PuBuGn_d\", ax=ax)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb870c8e3c36854c60282c30b1e3fb091e769329","_cell_guid":"18b10489-d892-40cc-8f71-35885a5caaed"},"cell_type":"markdown","source":"# Creating test data\nTo evaluate the trained models we'll need a **test set**. Evaluating on the train data would not be correct because the models are trained to minimize their cost function. \n\nFirst we combine the TextCounts variables with the CleanText variable.\n\n**NOTE: **Initially, I made the mistake to do execute TextCounts and CleanText in the GridSearchCV below. This took too long as it applies these functions each run of the GridSearch. It suffices to run them only once."},{"metadata":{"collapsed":true,"_uuid":"ff3f7a17f2b17fbfd43c24f33a061446fb502ca8","_cell_guid":"ccee501f-44a6-4f0d-9b6a-6bdf8713dd12","trusted":false},"cell_type":"code","source":"df_model = df_eda\ndf_model['clean_text'] = sr_clean\ndf_model.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79267622616a04aff402157783c5ed13a911dca6","_cell_guid":"509efba0-9d31-4c85-aef3-613cd1c6b17f"},"cell_type":"markdown","source":"So df_model now contains several variables. However, our vectorizers (see below) will only need the *clean_text* variable. The TextCounts variables can be added as such. To specifically select columns, I wrote the class **ColumnExtractor** below. This can be used in the Pipeline afterwards."},{"metadata":{"collapsed":true,"_uuid":"b6354efffb71c5a998ddf7f206aebd6c3324c117","_cell_guid":"b9b66faf-2fc6-4c50-9e1f-89b8dc5df13a","trusted":false},"cell_type":"code","source":"class ColumnExtractor(TransformerMixin, BaseEstimator):\n    def __init__(self, cols):\n        self.cols = cols\n\n    def transform(self, X, **transform_params):\n        return X[self.cols]\n\n    def fit(self, X, y=None, **fit_params):\n        return self","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"6ab9296159749e4525244fae6d6f4e6a37121c93","_cell_guid":"df742ade-52d3-4b47-80b0-1f7cc26545eb","trusted":false},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df_model.drop('airline_sentiment', axis=1), df_model.airline_sentiment, test_size=0.1, random_state=37)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"556b12393f591c21ac439bf3a0a9b7cf2fbbfd5b","_cell_guid":"a636aca6-1eed-4b59-ac7a-61b1cbcf10d6"},"cell_type":"markdown","source":"## Hyperparameter tuning and cross-validation\nAs we will see below, the vectorizers and classifiers all have configurable parameters. In order to chose the best parameters, we need to evaluate on a separate validation set that was not used during the training. However, using only one validation set may not produce reliable validation results. Due to chance you might have a good model performance on the validation set. If you would split the data otherwise, you might end up with other results. To get a more accurate estimation, we perform **cross-validation**. \n\nWith cross-validation the data is split into a train and validation set multiple times. The evaluation metric is then averaged over the different folds. Luckily, GridSearchCV applies cross-validation out-of-the-box.\n\nTo find the best parameters for both a vectorizer and classifier, we create a **Pipeline**. All this is put into a function for ease of use.\n\n### Evaluation metrics\nBy default GridSearchCV uses the default scorer to compute the *best_score_*. For both the MultiNomialNb and LogisticRegression this default scoring metric is the accuracy. \n\nIn our function *grid_vect* we additionally generate the *classification_report* on the test data. This provides some interesting metrics **per target class**, which might be more appropriate here. These metrics are the **precision, recal and F1 score.**\n\n* **Precision: ** Of all rows we predicted to be a certain class, how many did we correctly predict?\n* **Recall: ** Of all rows of a certain class, how many did we correctly predict?\n* **F1 score: ** Harmonic mean of Precision and Recall.\n\nPrecision and Recall can be calculated with the elements of the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix)\n\n$$Precision = {TP \\over TP + FP}$$\n\n\n$$Recall = {TP \\over TP + FN}$$\n\n\n$$F1 = {2*{Precision*Recall \\over Precision + Recall}}$$"},{"metadata":{"collapsed":true,"_uuid":"c4e69eaf67e587b05ca4e8da2bdecfbff8932e06","_cell_guid":"087a0727-fac6-4415-a8a0-b0c82df63903","trusted":false},"cell_type":"code","source":"# Based on http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html\ndef grid_vect(clf, parameters_clf, X_train, X_test, parameters_text=None, vect=None, is_w2v=False):\n    \n    textcountscols = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n                      ,'count_mentions','count_urls','count_words']\n    \n    if is_w2v:\n        w2vcols = []\n        for i in range(SIZE):\n            w2vcols.append(i)\n        features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n                                 , ('w2v', ColumnExtractor(cols=w2vcols))]\n                                , n_jobs=-1)\n    else:\n        features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n                                 , ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text')), ('vect', vect)]))]\n                                , n_jobs=-1)\n\n    \n    pipeline = Pipeline([\n        ('features', features)\n        , ('clf', clf)\n    ])\n    \n    # Join the parameters dictionaries together\n    parameters = dict()\n    if parameters_text:\n        parameters.update(parameters_text)\n    parameters.update(parameters_clf)\n\n    # Make sure you have scikit-learn version 0.19 or higher to use multiple scoring metrics\n    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=5)\n    \n    print(\"Performing grid search...\")\n    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n    print(\"parameters:\")\n    pprint(parameters)\n\n    t0 = time()\n    grid_search.fit(X_train, y_train)\n    print(\"done in %0.3fs\" % (time() - t0))\n    print()\n\n    print(\"Best CV score: %0.3f\" % grid_search.best_score_)\n    print(\"Best parameters set:\")\n    best_parameters = grid_search.best_estimator_.get_params()\n    for param_name in sorted(parameters.keys()):\n        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n        \n    print(\"Test score with best_estimator_: %0.3f\" % grid_search.best_estimator_.score(X_test, y_test))\n    print(\"\\n\")\n    print(\"Classification Report Test Data\")\n    print(classification_report(y_test, grid_search.best_estimator_.predict(X_test)))\n                        \n    return grid_search","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e8f816603ce6030c8ea9d49783701e897db1688","_cell_guid":"01574750-6449-4965-9dfd-3d0ac5ccc34e"},"cell_type":"markdown","source":"### Parameter grids for GridSearchCV"},{"metadata":{"collapsed":true,"_uuid":"193739bf202f607a7f6807738fe4c398af49f5e3","_cell_guid":"9212c557-3369-41ba-9162-742fa60eb17e","trusted":false},"cell_type":"code","source":"# Parameter grid settings for the vectorizers (Count and TFIDF)\nparameters_vect = {\n    'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n    'features__pipe__vect__ngram_range': ((1, 1), (1, 2)),\n    'features__pipe__vect__min_df': (1,2)\n}\n\n\n# Parameter grid settings for MultinomialNB\nparameters_mnb = {\n    'clf__alpha': (0.25, 0.5, 0.75)\n}\n\n\n# Parameter grid settings for LogisticRegression\nparameters_logreg = {\n    'clf__C': (0.25, 0.5, 1.0),\n    'clf__penalty': ('l1', 'l2')\n}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0460417e826faaec6753c344d184415775afbf7f","_cell_guid":"8793746e-2824-4070-a65d-e9657be8346a"},"cell_type":"markdown","source":"## Classifiers\nHere we will compare the performance of a MultinomailNB and LogisticRegression."},{"metadata":{"collapsed":true,"_uuid":"008942f2740a960f69ef61eb9b7eade21609104c","_cell_guid":"36321c02-35d4-4251-8191-6d470bad1a46","trusted":false},"cell_type":"code","source":"mnb = MultinomialNB()\nlogreg = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c21acf0845975a8bb319a41826499742d229999d","_cell_guid":"cb2dc7e1-0a2c-4e10-b98d-de222e0646a4"},"cell_type":"markdown","source":"## CountVectorizer\nTo use words in a classifier, we need to convert the words to numbers. This can be done with a CountVectorizer. Sklearn's **CountVectorizer** takes all words in all tweets, assigns an ID and counts the frequency of the word per tweet. This *bag of words* can then be used as input for a classifier. It is what is called a **sparse** data set, meaning that each record will have many zeroes for the words not occurring in the tweet."},{"metadata":{"collapsed":true,"_uuid":"c3df430fa01c37c4545c5051eba607a42727786d","_cell_guid":"de29adfc-1c07-4feb-8c91-c9899cb2808e","trusted":false},"cell_type":"code","source":"countvect = CountVectorizer()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"7b430d09e131f7f62d528d471c7eb8f8445b7dba","_cell_guid":"afb5ec51-b86f-40bf-ab9d-3371c4a90d92","trusted":false},"cell_type":"code","source":"# MultinomialNB\nbest_mnb_countvect = grid_vect(mnb, parameters_mnb, X_train, X_test, parameters_text=parameters_vect, vect=countvect)\n#joblib.dump(best_mnb_countvect, '../output/best_mnb_countvect.pkl')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"036edeb05520a608a42eec7342234683ae711eaa","_cell_guid":"542fc0be-11a4-41a4-8c81-2cd424dd4d69","trusted":false},"cell_type":"code","source":"# LogisticRegression\nbest_logreg_countvect = grid_vect(logreg, parameters_logreg, X_train, X_test, parameters_text=parameters_vect, vect=countvect)\n#joblib.dump(best_logreg_countvect, '../output/best_logreg_countvect.pkl')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa577f613aafd434a375502edaa66d3ceca23aaa","_cell_guid":"dbaf51ca-906d-4af1-9055-22c791f6de07"},"cell_type":"markdown","source":"## TF-IDF\nOne issue with CountVectorizer is that there might be words that occur frequently in observations of the target classes. These words do not have discriminatory information and can be removed. **TF-IDF (term frequency - inverse document frequency)** can be used to downweight these frequent words.\n\n$$tfidf(t,d) = tf(t,d)*idf(t,d)$$\n\nwhere tf(t,d) is the number of times term *t* occurs in document *d*. The inverse document frequency can be computed as follows:\n\n$$idf(t,d) = log{n_d \\over 1 + df(d,t)}$$\n\n* $n_d$ is the number of documents\n* df(d,t) is the number of documents that contain term *t*\n\nWe see that words that occur in many documents will have a low idf. By adding 1 to the denominator, we avoid having an idf equal to zero for words that occur in all documents."},{"metadata":{"collapsed":true,"_uuid":"0c5279535d8dacb86b3560eb3257a548e9837126","_cell_guid":"1f7ed46a-4f7b-4671-b77d-1fd800dc2b15","trusted":false},"cell_type":"code","source":"tfidfvect = TfidfVectorizer()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"f9c84cb6a4c16d9fd850f1d94ecdb63f3f351c16","_cell_guid":"4892673a-2f32-4c60-ae60-4c38f6f95285","trusted":false},"cell_type":"code","source":"# MultinomialNB\nbest_mnb_tfidf = grid_vect(mnb, parameters_mnb, X_train, X_test, parameters_text=parameters_vect, vect=tfidfvect)\n#joblib.dump(best_mnb_tfidf, '../output/best_mnb_tfidf.pkl')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"95e60d825eb7f71de879ed3dcb54feaae461d2f9","_cell_guid":"214a2383-9cb8-4d90-a326-f3018118ffff","trusted":false},"cell_type":"code","source":"# LogisticRegression\nbest_logreg_tfidf = grid_vect(logreg, parameters_logreg, X_train, X_test, parameters_text=parameters_vect, vect=tfidfvect)\n#joblib.dump(best_logreg_tfidf, '../output/best_logreg_tfidf.pkl')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0f95a5ca1fc981f625bcfabad73ab23aaf3c4dc","_cell_guid":"eabc2c85-1c0e-4f10-a86b-8e9a9010b013"},"cell_type":"markdown","source":"## Word2Vec\nAnother way of converting the words in the tweets to numerical values can be achieved with Word2Vec. Word2Vec maps each word in a multi-dimensional space. It does this by taking into account the context in which a word appears in the tweets. As a result, words that are semantically similar are also close to each other in the multi-dimensional space. \n\nThe Word2Vec algorithm is implemented in the [gensim](https://radimrehurek.com/gensim/models/word2vec.html) package.\n\nThe Word2Vec algorithm uses lists of words as input. For that purpose we use the **word_tokenize** method of the the nltk package."},{"metadata":{"collapsed":true,"_uuid":"c025fc3ca889f327166163c06ed3bdc4b7d0693e","_cell_guid":"15a6a3ce-90d5-4414-b2b6-4d2c64317fa6","trusted":false},"cell_type":"code","source":"SIZE = 50\n\nX_train['clean_text_wordlist'] = X_train.clean_text.apply(lambda x : word_tokenize(x))\nX_test['clean_text_wordlist'] = X_test.clean_text.apply(lambda x : word_tokenize(x))\n\nmodel = gensim.models.Word2Vec(X_train.clean_text_wordlist\n                 , min_count=1\n                 , size=SIZE\n                 , window=5\n                 , workers=4)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"2d0e5851469b48ed7aaaa683360a478f7aa68312","_cell_guid":"147ac98f-81f4-4812-b0e6-82be4e62b4f7","trusted":false},"cell_type":"code","source":"model.most_similar('plane', topn=3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d1d10d0ab55e563c21bc2e8fdbf661c85f86861","_cell_guid":"8ab070a7-f9fb-419e-ae08-8354678b6d44"},"cell_type":"markdown","source":"The Word2Vec model provides a vocabulary of the words in the corpus together with their vector values. The number of vector values is equal to the chosen **size**. These are the dimensions on which each word is mapped in the multi-dimensional space.\n\nWords with an occurrence less than **min_count** are not kept in the vocabulary. \n**NOTE: **A side effect of the **min_count** parameter is that some tweets could have no vector values. This is would be the case when the word(s) in the tweet occur in less than *min_count* tweets. Due to the small corpus of tweets, there is a risk of this happening in our case. Therefore we set the min_count value equal to 1.\n\nThe tweets can have a different number of vectors, depending on the number of words it contains. To use this output for modeling we will aggregate the vectors per tweet to have the same number (i.e. *size*) of input variables per tweet. Therefore we will take the average of all vectors per tweet. We do this with the function **compute_avg_w2v_vector**. In this function we also check whether the words in the tweet occur in the vocabulary of the word2vec model. If not, a list filled with 0.0 is returned. Else the average of the word vectors."},{"metadata":{"collapsed":true,"_uuid":"8f8bb64ea5c614fde257d5598ffe15f96d7d1007","_cell_guid":"e3e2cc96-9e47-4008-8dba-4b38b9d56e9a","trusted":false},"cell_type":"code","source":"def compute_avg_w2v_vector(w2v_dict, tweet):\n    list_of_word_vectors = [w2v_dict[w] for w in tweet if w in w2v_dict.vocab.keys()]\n    \n    if len(list_of_word_vectors) == 0:\n        result = [0.0]*SIZE\n    else:\n        result = np.sum(list_of_word_vectors, axis=0) / len(list_of_word_vectors)\n        \n    return result","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"c4ef3f27b39715b2b6c8d1b8097247df8be17c49","_cell_guid":"a565bf07-dc13-47c4-b15a-34d76b4f9709","trusted":false},"cell_type":"code","source":"X_train_w2v = X_train['clean_text_wordlist'].apply(lambda x: compute_avg_w2v_vector(model.wv, x))\nX_test_w2v = X_test['clean_text_wordlist'].apply(lambda x: compute_avg_w2v_vector(model.wv, x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da4f8b5208928a33b11a695cf632ca48312b9914","_cell_guid":"9960b357-36b9-464f-ab9b-847c1c2b94e4"},"cell_type":"markdown","source":"This gives us a Series with a vector of dimension equal to SIZE. Now we will split this vector and create a DataFrame with each vector value in a separate column. That way we can concatenate the word2vec variables to the other TextCounts variables. We need to reuse the index of X_train and X_test respectively. Otherwise this will give issues (duplicates) in the concatenation later on."},{"metadata":{"collapsed":true,"_uuid":"2e179a61852c0104fa69778da4112458947df849","_cell_guid":"8a4fdcd5-c7ca-4466-9cb3-4bf4bd9168a8","trusted":false},"cell_type":"code","source":"X_train_w2v = pd.DataFrame(X_train_w2v.values.tolist(), index= X_train.index)\nX_test_w2v = pd.DataFrame(X_test_w2v.values.tolist(), index= X_test.index)\n\n# Concatenate with the TextCounts variables\nX_train_w2v = pd.concat([X_train_w2v, X_train.drop(['clean_text', 'clean_text_wordlist'], axis=1)], axis=1)\nX_test_w2v = pd.concat([X_test_w2v, X_test.drop(['clean_text', 'clean_text_wordlist'], axis=1)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7af9c05fc41ff9e21b4eaf14a29896ea894cb42","_cell_guid":"bd3dcab9-7142-4ad8-92ee-c3d38b3ed728"},"cell_type":"markdown","source":"**NOTE: **We only consider LogisticRegression as we have negative values in the Word2Vec vectors. MultinomialNB assumes that the variables have a [multinomial distribution](https://en.wikipedia.org/wiki/Multinomial_distribution) which cannot contain negative values."},{"metadata":{"collapsed":true,"_uuid":"f3f0f72c6f9026dcbf7968c051e278be6e51c142","_cell_guid":"ec60ef90-c066-4122-8127-f6baae769b82","trusted":false},"cell_type":"code","source":"best_logreg_w2v = grid_vect(logreg, parameters_logreg, X_train_w2v, X_test_w2v, is_w2v=True)\n#joblib.dump(best_logreg_w2v, '../output/best_logreg_w2v.pkl')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b82428854dd5fc8e830a8c028ecc9d290ae9aefc","_cell_guid":"c7477bd7-6d56-4bf2-9449-681b88d148ff"},"cell_type":"markdown","source":"## Conclusion\n* Both classifiers achieve the best results when using the features of the CountVectorizer\n* Overall, Logistic Regression outperforms the Multinomial Naive Bayes classifier\n* The best performance on the test set comes from the LogisticRegression with features from CountVectorizer. \n\nBest parameters:\n* C value of 1\n* L2 regularization\n* max_df: 0.5 or maximum document frequency of 50%.\n* min_df: 1 or the words need to appear in at least 2 tweets\n* ngram_range: (1, 2), both single words as bi-grams are used\n\nEvaluation metrics:\n* A **test accuracy** of 81,3%, which is better than what we would achieve by setting the prediction for all observations to the majority class (*negative* which would give 63% accuracy).\n* The **Precision** is rather high for all three classes. For instance, of all cases that we predict as negative, 80% is indeed negative.\n* The **Recall** for the neutral class is low. Of all neutral cases in our test data, we only predict 48% as being neutral."},{"metadata":{"_uuid":"ff1a35d16acc301b686083679d0f1c1abcff1467","_cell_guid":"636eb271-dd42-45b9-be15-f2eebdcbacc6"},"cell_type":"markdown","source":"# Apply the best model on new tweets\nJust for the fun we will use the best model and apply it to some new tweets that contain *@VirginAmerica*. I selected 3 negative and 3 positive tweets by hand. \n\nThanks to the GridSearchCV, we now know what are the best hyperparameters. So now we can train the best model on **all training data**, including the test data that we split off before."},{"metadata":{"collapsed":true,"_uuid":"85c665cf6d49f4c6d9ce9d317b59edcd8e99421c","_cell_guid":"09062c4d-74af-4666-ad5b-7a4fdd5d1609","trusted":false},"cell_type":"code","source":"textcountscols = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n                      ,'count_mentions','count_urls','count_words']\n    \nfeatures = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n                         , ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text'))\n                                              , ('vect', CountVectorizer(max_df=0.5, min_df=1, ngram_range=(1,2)))]))]\n                       , n_jobs=-1)\n\npipeline = Pipeline([\n    ('features', features)\n    , ('clf', LogisticRegression(C=1.0, penalty='l2'))\n])\n\nbest_model = pipeline.fit(df_model.drop('airline_sentiment', axis=1), df_model.airline_sentiment)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"40be183cab101f741e096d8f9bec5ef6c4ca6611","_cell_guid":"85b45b28-cd70-4e14-95db-f247b084760c"},"cell_type":"markdown","source":"## New positive tweets"},{"metadata":{"collapsed":true,"_uuid":"475e26f89d0cf8b16e5cf6d223fe357ab8c676ce","_cell_guid":"68f9c4fe-4783-49c8-b712-efc7aac3a6a9","trusted":false},"cell_type":"code","source":"new_positive_tweets = pd.Series([\"Thank you @VirginAmerica for you amazing customer support team on Tuesday 11/28 at @EWRairport and returning my lost bag in less than 24h! #efficiencyiskey #virginamerica\"\n                      ,\"Love flying with you guys ask these years.  Sad that this will be the last trip 😂   @VirginAmerica  #LuxuryTravel\"\n                      ,\"Wow @VirginAmerica main cabin select is the way to fly!! This plane is nice and clean & I have tons of legroom! Wahoo! NYC bound! ✈️\"])\n\ndf_counts_pos = tc.transform(new_positive_tweets)\ndf_clean_pos = ct.transform(new_positive_tweets)\ndf_model_pos = df_counts_pos\ndf_model_pos['clean_text'] = df_clean_pos\n\nbest_model.predict(df_model_pos).tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7bd24b86003abb43a723c40aefcb1aa2efe5b1c6","_cell_guid":"92f4e8e4-c3cb-4c75-98d7-808df9b7d957"},"cell_type":"markdown","source":"## New negative tweets"},{"metadata":{"collapsed":true,"_uuid":"08d6ef70b9cf83ba7090bb549a843d46e526bf89","_cell_guid":"1cfdc5db-efe3-4df4-a547-25aa1144e46f","trusted":false},"cell_type":"code","source":"new_negative_tweets = pd.Series([\"@VirginAmerica shocked my initially with the service, but then went on to shock me further with no response to what my complaint was. #unacceptable @Delta @richardbranson\"\n                      ,\"@VirginAmerica this morning I was forced to repack a suitcase w a medical device because it was barely overweight - wasn't even given an option to pay extra. My spouses suitcase then burst at the seam with the added device and had to be taped shut. Awful experience so far!\"\n                      ,\"Board airplane home. Computer issue. Get off plane, traverse airport to gate on opp side. Get on new plane hour later. Plane too heavy. 8 volunteers get off plane. Ohhh the adventure of travel ✈️ @VirginAmerica\"])\n\ndf_counts_neg = tc.transform(new_negative_tweets)\ndf_clean_neg = ct.transform(new_negative_tweets)\ndf_model_neg = df_counts_neg\ndf_model_neg['clean_text'] = df_clean_neg\n\nbest_model.predict(df_model_neg).tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4faacdd241c5bc7801da69d07dc2cd45fde6a333","_cell_guid":"8e3721bb-0c96-427f-ae08-b7d7f0be38ba"},"cell_type":"markdown","source":"Great! The model classifies all of the tweets correctly. Obviously, a much larger test set should be used to correctly assess the model's performance. But you get the idea what you can do with this."}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}