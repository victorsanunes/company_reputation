{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = \"47686340-6AB44t7rmWM5s5Lz0URIWe7RL8Ib8NIzLO6U1z1qd\"\n",
    "access_token_secret = \"vpwhFGtADN7HTWDj2SHb21KiBoO4YEu5ywA5fo5ydtTKj\"\n",
    "consumer_key = \"HHE1PyMtUGtnNvDHvgckcd5Ee\"\n",
    "consumer_key_secret = \"Rv2MUPbDrxM0hvWda2lrrmsYHBe3e90SDCIqVnP3CJyUNE1Xsn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "from tweepy import OAuthHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(consumer_key, consumer_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    " \n",
    "# api = tweepy.API(auth)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTweetsJson(query, since_date, max_tweets, lang=None):\n",
    "    searched_tweets = []\n",
    "    last_id = -1\n",
    "\n",
    "    while len(searched_tweets) < max_tweets:\n",
    "        count = max_tweets - len(searched_tweets)\n",
    "        try:\n",
    "            new_tweets = api.search(q=query, \n",
    "                                    count=count, \n",
    "                                    max_id=str(last_id - 1),\n",
    "#                                    lang=lang,\n",
    "                                   since=since_date)\n",
    "            if not new_tweets:\n",
    "                break\n",
    "\n",
    "\n",
    "            searched_tweets.extend(new_tweets)\n",
    "            last_id = new_tweets[-1].id\n",
    "        except tweepy.TweepError as e:\n",
    "            # depending on TweepError.code, one may want to retry or wait\n",
    "            # to keep things simple, we will give up on an error\n",
    "            break\n",
    "        return searched_tweets\n",
    "    \n",
    "def getTweetText(tweet_json, rt):\n",
    "    tweets_text = list()\n",
    "    if(rt):\n",
    "        for tweet in tweet_json:\n",
    "            tweets_text.append(tweet.text.encode('utf-8'))\n",
    "    else:\n",
    "        for tweet in tweet_json:\n",
    "            if(not tweet.retweeted) and ('RT @' not in tweet.text):\n",
    "                tweets_text.append(tweet.text.encode('utf-8'))\n",
    "    return tweets_text\n",
    "\n",
    "def getTweetTextAndDate(tweet_json, rt):\n",
    "    tweets_text = dict()\n",
    "    i = 0\n",
    "    if(rt):\n",
    "        for tweet in tweet_json:\n",
    "            tweets_text[i] = dict()\n",
    "            tweets_text[i][\"text\"] = (tweet.text.encode('utf-8'))\n",
    "            tweets_text[i][\"date\"] = (tweet.created_at)\n",
    "            i = i + 1\n",
    "    else:\n",
    "        for tweet in tweet_json:\n",
    "            if(not tweet.retweeted) and ('RT @' not in tweet.text):\n",
    "                tweets_text[i] = dict()\n",
    "                tweets_text[i][\"text\"] = (tweet.text.encode('utf-8'))\n",
    "                tweets_text[i][\"date\"] = (tweet.created_at)\n",
    "                i = i + 1\n",
    "    return tweets_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeTweetTextToCsv(filename, tweet_text):\n",
    "    csvFile = open(filename, 'a')\n",
    "    i = 0\n",
    "    #Use csv Writer\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "    for tweet in tweet_text:\n",
    "        csvWriter.writerow([i, tweet])\n",
    "        i = i + 1\n",
    "\n",
    "def writeTweetTextandDateToCsv(filename, tweet_text_and_date):\n",
    "    csvFile = open(filename, 'a')\n",
    "\n",
    "    #Use csv Writer\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "    for tweet_idx in tweet_text_and_date:\n",
    "        csvWriter.writerow([tweet_text_and_date[tweet_idx][\"date\"], tweet_text_and_date[tweet_idx][\"text\"]])\n",
    "#         print((tweet_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json = getTweetsJson(query=\"@LATAM_BRA\",\n",
    "                           since_date=\"2018-06-07\",\n",
    "                           max_tweets = 10000\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = getTweetText(tweet_json, rt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text_and_date = getTweetTextAndDate(tweet_json, rt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writeTweetTextToCsv(\"latam_bra.csv\", tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeTweetTextandDateToCsv(\"latam_bra(3).csv\", tweet_text_and_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse codigo abaixo eh porque na funcao nao estava funcionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "searched_tweets = []\n",
    "last_id = -1\n",
    "max_tweets = 100000\n",
    "query = \"@VoeGOLoficial\"\n",
    "\n",
    "while len(searched_tweets) < max_tweets:\n",
    "    count = max_tweets - len(searched_tweets)\n",
    "    try:\n",
    "        new_tweets = api.search(q=query, \n",
    "                                count=count, \n",
    "                                max_id=str(last_id - 1),\n",
    "                                   lang=\"pt\",\n",
    "                               since='2018-06-07')\n",
    "        if not new_tweets:\n",
    "            break\n",
    "\n",
    "\n",
    "        searched_tweets.extend(new_tweets)\n",
    "        last_id = new_tweets[-1].id\n",
    "    except tweepy.TweepError as e:\n",
    "        # depending on TweepError.code, one may want to retry or wait\n",
    "        # to keep things simple, we will give up on an error\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text_and_date = getTweetTextAndDate(searched_tweets, rt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeTweetTextandDateToCsv(\"gol_pt(1).csv\", tweet_text_and_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
